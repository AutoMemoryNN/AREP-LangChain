# translate.py
import os
from dotenv import load_dotenv
from langchain.chat_models import init_chat_model
from langchain_core.prompts import ChatPromptTemplate

# Cargar variables de entorno desde el archivo .env
load_dotenv()

def main():
    # Verificar que la API key estÃ¡ configurada
    if not os.environ.get("OPENAI_API_KEY"):
        print("Error: API key de OpenAI no encontrada. Por favor, configura la variable de entorno OPENAI_API_KEY.")
        return
    
    # Configurar LangSmith si estÃ¡ habilitado
    if os.environ.get("LANGSMITH_API_KEY") and os.environ.get("LANGSMITH_TRACING") == "true":
        print("LangSmith tracing habilitado para depuraciÃ³n y monitoreo.")
    
    print("ğŸ”¹ Inicializando modelo de chat...")
    # Inicializar el modelo de chat
    model = init_chat_model("gpt-4o-mini", model_provider="openai")
    
    # Crear una plantilla de prompt para la traducciÃ³n
    print("ğŸ”¹ Creando plantilla de prompt...")
    system_template = "Translate the following from English into {language}"
    prompt_template = ChatPromptTemplate.from_messages(
        [("system", system_template), ("user", "{text}")]
    )
    
    # InteracciÃ³n con el usuario
    print("\nğŸŒ Traductor de Idiomas con LangChain ğŸŒ")
    print("----------------------------------")
    
    while True:
        text = input("\nğŸ“ Texto en inglÃ©s (o 'salir' para terminar): ")
        if text.lower() in ["salir", "exit", "quit"]:
            print("ğŸ‘‹ Â¡Hasta pronto!")
            break
        
        language = input("ğŸŒ Idioma de destino (e.g., Spanish, French, Italian): ")
        
        print("\nğŸ”„ Traduciendo...")
        
        # Formatear el prompt con los valores proporcionados
        prompt = prompt_template.invoke({"language": language, "text": text})
        
        # Invocar el modelo para obtener la traducciÃ³n
        try:
            response = model.invoke(prompt)
            print(f"\nâœ… TraducciÃ³n ({language}):")
            print(f"ğŸ—£ï¸ {response.content}")
            
            # Mostrar informaciÃ³n de tokens si estÃ¡ disponible
            if hasattr(response, 'response_metadata') and 'token_usage' in response.response_metadata:
                usage = response.response_metadata['token_usage']
                print(f"\nâ„¹ï¸ Tokens utilizados: {usage.get('total_tokens', 'N/A')}")
        
        except Exception as e:
            print(f"\nâŒ Error durante la traducciÃ³n: {str(e)}")

if __name__ == "__main__":
    main()